{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e8719881-b067-4348-b595-a5353298c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ca748c2b-4249-41c3-8efa-a86ca9872139",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1ac45631-459d-4fa3-9f8b-211e80ca1226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b32cbd-59d6-4dc6-9f60-b550e4de4eab",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "f7459a0f-4a62-48c6-9539-27276524679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImpurityDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, fixed_features, labels, feature_scaler=None, label_r_scaler=None, label_i_scaler=None, device=None):\n",
    "        assert len(labels) % 2 == 0\n",
    "        \n",
    "        self.fixed_features = fixed_features\n",
    "        self.labels = labels\n",
    "        self.n_samples = len(dataframe)\n",
    "        \n",
    "        self.output_length = 2\n",
    "        self.input_length = len(fixed_features) + len(labels) - self.output_length\n",
    "        self.sequence_length = len(labels) // self.output_length # how many auto regressive steps we have to take; not SEQ_LEN of the transformer!\n",
    "\n",
    "        df_features = dataframe[fixed_features]\n",
    "        df_labels = dataframe[labels]\n",
    "        \n",
    "        if feature_scaler is not None and label_r_scaler is not None and label_i_scaler is not None:\n",
    "            xs = feature_scaler.transform(df_features)\n",
    "            \n",
    "            ys_r = label_r_scaler.transform(df_labels[df_labels.columns[::2]])\n",
    "            ys_i = label_i_scaler.transform(df_labels[df_labels.columns[1::2]])\n",
    "            \n",
    "            ys = np.empty((ys_r.shape[0], ys_r.shape[1] * 2), dtype=ys_r.dtype)\n",
    "            ys[:, ::2] = ys_r  # fill even indices with real parts\n",
    "            ys[:, 1::2] = ys_i  # fill odd indices with imaginary parts\n",
    "        else:\n",
    "            xs = df_features.values\n",
    "            ys = df_labels.values\n",
    "        \n",
    "        xss = np.zeros((self.n_samples * self.sequence_length, self.input_length))\n",
    "        yss = np.zeros((self.n_samples * self.sequence_length, self.input_length, self.output_length))\n",
    "\n",
    "        ff_len = len(self.fixed_features)\n",
    "        \n",
    "        for i in range(self.n_samples * self.sequence_length):\n",
    "            j = i // self.sequence_length\n",
    "            end = (i % self.sequence_length) * self.output_length\n",
    "            \n",
    "            xss[i, :ff_len] = xs[j, :]\n",
    "            xss[i, ff_len:ff_len+end] = ys[j, :end]\n",
    "\n",
    "            yss[i, ff_len+end-1:ff_len+end, :] = ys[j, end:end + self.output_length].reshape(self.output_length)\n",
    "       \n",
    "        xss = xss.reshape(self.n_samples * self.sequence_length, self.input_length, 1)\n",
    "\n",
    "        self.feature_data = torch.tensor(xss, dtype=torch.float).to(device)\n",
    "        self.label_data = torch.tensor(yss, dtype=torch.float).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples * self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.feature_data[idx], self.label_data[idx], (len(self.fixed_features) - 1 + (idx % self.sequence_length) * self.output_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "e4745dbe-e866-40ee-8014-320fb6de09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scalers(dataframe, fixed_features, labels, test_size=0.1, random_state=None):\n",
    "    train_df, _ = train_test_split(dataframe, test_size=test_size, random_state=random_state)\n",
    "    df_features = train_df[fixed_features]\n",
    "    df_labels = train_df[labels]\n",
    "    \n",
    "    feature_scaler = StandardScaler()\n",
    "    label_r_scaler = StandardScaler()\n",
    "    label_i_scaler = StandardScaler()\n",
    "\n",
    "    feature_scaler.fit(df_features)\n",
    "    label_r_scaler.fit(df_labels[df_labels.columns[::2]]) # get only real columns\n",
    "    label_i_scaler.fit(df_labels[df_labels.columns[1::2]]) # get only imaginary columns\n",
    "\n",
    "    return feature_scaler, label_r_scaler, label_i_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d1bb7fbd-7c0a-495d-bc24-772b235a90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/20230825_144318_10k_EVDoubExp-TExp-wmax5-sparse-hyb_with_perturbation.csv'\n",
    "\n",
    "#fixed_features = ['beta', 'U', 'Eimp', 'E1', 'E2', 'E3', 'V1', 'V2', 'V3']\n",
    "#fixed_features = ['beta', 'E1', 'E2', 'E3', 'V1', 'V2', 'V3']\n",
    "fixed_features = ['beta', 'E1', 'E2', 'E3', 'V1', 'V2', 'V3', 'ReFso1', 'ImFso1', 'ReFso3', 'ImFso3', 'ReFso5', 'ImFso5', 'ReFso7', 'ImFso7', 'ReFso9', 'ImFso9', 'ReFso11', 'ImFso11', 'ReFso13', 'ImFso13', 'ReFso15', 'ImFso15', 'ReFso17', 'ImFso17', 'ReFso19', 'ImFso19', 'ReFso21', 'ImFso21', 'ReFso23', 'ImFso23', 'ReFso25', 'ImFso25', 'ReFso29', 'ImFso29', 'ReFso33', 'ImFso33', 'ReFso37', 'ImFso37', 'ReFso43', 'ImFso43', 'ReFso49', 'ImFso49', 'ReFso57', 'ImFso57', 'ReFso69', 'ImFso69', 'ReFso83', 'ImFso83', 'ReFso101', 'ImFso101', 'ReFso127', 'ImFso127', 'ReFso165', 'ImFso165', 'ReFso237', 'ImFso237', 'ReFso399', 'ImFso399', 'ReFso1207', 'ImFso1207']\n",
    "labels = ['ReSf1', 'ImSf1', 'ReSf3', 'ImSf3', 'ReSf5', 'ImSf5', 'ReSf7', 'ImSf7', 'ReSf9', 'ImSf9', 'ReSf11', 'ImSf11', 'ReSf13', 'ImSf13', 'ReSf15', 'ImSf15', 'ReSf17', 'ImSf17', 'ReSf19', 'ImSf19', 'ReSf21', 'ImSf21', 'ReSf23', 'ImSf23', 'ReSf25', 'ImSf25', 'ReSf29', 'ImSf29', 'ReSf33', 'ImSf33', 'ReSf37', 'ImSf37', 'ReSf43', 'ImSf43', 'ReSf49', 'ImSf49', 'ReSf57', 'ImSf57', 'ReSf69', 'ImSf69', 'ReSf83', 'ImSf83', 'ReSf101', 'ImSf101', 'ReSf127', 'ImSf127', 'ReSf165', 'ImSf165', 'ReSf237', 'ImSf237', 'ReSf399', 'ImSf399', 'ReSf1207', 'ImSf1207']\n",
    "\n",
    "df = pd.read_csv(file_path, skiprows=4) # we skip the first four lines, because they are just metadata\n",
    "df = df[fixed_features + labels]\n",
    "\n",
    "validation_size = 0.1 # 90% training, 10% for validation\n",
    "\n",
    "feature_scaler, label_r_scaler, label_i_scaler = compute_scalers(df, fixed_features, labels, validation_size, seed) # make sure we use the same seed, otherwise the two splits differ!\n",
    "#dataset = ImpurityDataset(df, fixed_features, labels, device=device)\n",
    "dataset = ImpurityDataset(df, fixed_features, labels, feature_scaler, label_r_scaler, label_i_scaler, device)  \n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, val_indices = train_test_split(indices, test_size=validation_size, random_state=seed)  # make sure we use the same seed, otherwise the two splits differ!\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "98f8b9d2-454a-41dd-bd6e-232135263d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.__getitem__(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23694fa-f39d-48b1-9a50-d815762d86ea",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "2581363e-4b96-4ef8-bf92-5f633aca6dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodingL(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=27):\n",
    "        super(PositionalEncodingL, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.positional_embedding = nn.Parameter(torch.zeros(max_len, d_model))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        position_encoded = self.positional_embedding[:, :].unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        x = x + position_encoded\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "2eee253d-b790-4860-bab8-305eb0ca7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodingF(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=27):\n",
    "        super(PositionalEncodingF, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "c648bc1c-a7b4-4b82-bf63-e06dd0967f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    fixed_features: int\n",
    "    labels: int\n",
    "\n",
    "    input_dim: int\n",
    "    output_dim: int\n",
    "    \n",
    "    d_model: int\n",
    "    nhead: int\n",
    "    num_layers: int\n",
    "    dim_feedforward: int\n",
    "    \n",
    "    dropout: float\n",
    "    activation: str\n",
    "    bias: bool\n",
    "\n",
    "class AutoregressiveTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, config, device):\n",
    "        super(AutoregressiveTransformer, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.sequence_length = config.fixed_features + config.labels - config.output_dim\n",
    "        \n",
    "        self.input_projection = nn.Linear(config.input_dim, config.d_model)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncodingL(config.d_model, dropout=config.dropout, max_len=self.sequence_length)\n",
    "        \n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=config.d_model, \n",
    "            nhead=config.nhead, \n",
    "            dim_feedforward=config.dim_feedforward, \n",
    "            dropout=config.dropout,\n",
    "            activation=config.activation, \n",
    "            batch_first=True, \n",
    "            norm_first=True, \n",
    "            bias=config.bias\n",
    "        )\n",
    "        \n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=config.num_layers)\n",
    "        \n",
    "        self.output_layer = nn.Linear(config.d_model, config.output_dim)\n",
    "        \n",
    "        self.att_mask = self.generate_mask(self.sequence_length, self.config.fixed_features, self.config.output_dim, device)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.input_projection(x)        \n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        output = self.transformer_decoder(x, x, tgt_mask=self.att_mask)\n",
    "        output = self.output_layer(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def generate_mask(self, sequence_length, fixed_features, output_dim, device):\n",
    "        assert (sequence_length - fixed_features) % output_dim == 0\n",
    "        \n",
    "        mask = torch.full((sequence_length, sequence_length), float('-inf'), device=device)\n",
    "        mask[:, :fixed_features] = 0 \n",
    "        \n",
    "        for i in range(fixed_features, sequence_length, output_dim):\n",
    "            mask[i:, i] = torch.tensor([0] * (sequence_length - i), device=device)\n",
    "            mask[i:, i+1] = torch.tensor([0] * (sequence_length - i), device=device)\n",
    "            \n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0842f-41f6-420c-b896-4b19f67805c3",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "5edc082b-3d45-4afb-95b6-4d2edaa703e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ModelConfig(\n",
    "    fixed_features = len(fixed_features),\n",
    "    labels = len(labels),\n",
    "    \n",
    "    input_dim = 1,\n",
    "    output_dim = 2,\n",
    "    \n",
    "    d_model = 128,\n",
    "    nhead = 4,\n",
    "    num_layers = 2,\n",
    "    dim_feedforward = 128 * 4,\n",
    "    \n",
    "    dropout = 0.1,\n",
    "    activation = 'gelu',\n",
    "    bias = True\n",
    ")\n",
    "\n",
    "model = AutoregressiveTransformer(config, device).to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "dec32597-9f94-42fc-a936-be7eb75d331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for inputs, targets, idx in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        masked_outputs = torch.zeros(outputs.shape, device=device)\n",
    "\n",
    "        for row, col in enumerate(idx):\n",
    "            masked_outputs[row, col] = outputs[row, col]\n",
    "        \n",
    "        loss = criterion(masked_outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "7d324c9b-2a4f-4b65-abcd-7ead8d07e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, targets, idx in val_loader:\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            masked_outputs = torch.zeros(outputs.shape, device=device)\n",
    "    \n",
    "            for row, col in enumerate(idx):\n",
    "                masked_outputs[row, col] = outputs[row, col]\n",
    "            \n",
    "            loss = criterion(masked_outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec0284b-7904-4dbc-b42d-69b6d367b8d6",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9067e6b-ea16-42e9-989b-ef6896481deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: Train Loss: 0.000493, Val Loss: 0.000253, Val MAPE: 27.547171\n",
      "Epoch   2: Train Loss: 0.000268, Val Loss: 0.000086, Val MAPE: 10.645461\n",
      "Epoch   3: Train Loss: 0.000238, Val Loss: 0.000094, Val MAPE: 12.192848\n",
      "Epoch   4: Train Loss: 0.000263, Val Loss: 0.000124, Val MAPE: 19.510052\n",
      "Epoch   5: Train Loss: 0.000182, Val Loss: 0.000094, Val MAPE: 12.316251\n",
      "Epoch   6: Train Loss: 0.000164, Val Loss: 0.000056, Val MAPE: 7.868703\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "    val_mape = validate_mape(model, len(fixed_features), val_loader, label_r_scaler, label_i_scaler, device)\n",
    "    print(f\"Epoch {(epoch+1):3d}: Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}, Val MAPE: {val_mape:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c375fecd-b79b-4a84-b5de-78ea7ed0d24b",
   "metadata": {},
   "source": [
    "### Manual model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c8c95-6a90-4792-a74e-302534c87e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mape(model, ff_len, val_loader, scaler_r, scaler_i, device, epsilon=1e-8):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, targets, idx in val_loader:\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            outputs = [(ii, outputs[i, ii]) for i, ii in enumerate(idx)]\n",
    "            targets = [(ii, targets[i, ii]) for i, ii in enumerate(idx)]\n",
    "            \n",
    "            outputs = torch.tensor(np.array([reverse_tranform_output(o, idx, ff_len, scaler_r, scaler_i) for idx, o in outputs]))\n",
    "            targets = torch.tensor(np.array([reverse_tranform_output(t, idx, ff_len, scaler_r, scaler_i) for idx, t in targets]))\n",
    "            \n",
    "            ape = torch.abs((targets - outputs) / (targets + epsilon))\n",
    "            mape = torch.mean(ape) * 100\n",
    "                    \n",
    "            total_loss += mape.item()\n",
    "            \n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4537b0-7c15-4d74-85bf-65d053516262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_tranform_output(data, index, ff_len, scaler_r, scaler_i):\n",
    "    data = data.cpu().numpy()\n",
    "    \n",
    "    data = np.tile(data, (27, 1))\n",
    "    i_seq = (index - (ff_len - 1)) // 2\n",
    "    \n",
    "    r = scaler_r.inverse_transform(data[:, ::2].reshape(1, -1)).reshape(-1, 1)[i_seq]\n",
    "    i = scaler_i.inverse_transform(data[:, 1::2].reshape(1, -1)).reshape(-1, 1)[i_seq]\n",
    "    \n",
    "    return np.concatenate((r, i), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45952c7e-e2d3-4aff-8810-7fd7693e104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_mape(model, len(fixed_features), val_loader, label_r_scaler, label_i_scaler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a0d1d-5db4-417d-8fed-c44ca4256892",
   "metadata": {},
   "source": [
    "### Sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "850f5ca1-bfd3-4716-9088-996e14a68c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(model, input, idx, sequence_length, ff_len, dim, device):\n",
    "    model.eval()\n",
    "\n",
    "    niters = (sequence_length - (ff_len - 1)) // 2\n",
    "    fixed_features = input[:ff_len]\n",
    "    \n",
    "    initial_input = torch.zeros(1, sequence_length, dim)\n",
    "    initial_input[0, :ff_len] = fixed_features\n",
    "    current_input = initial_input.to(device)\n",
    "\n",
    "    outputs = torch.zeros(niters + 1, 2, device = device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i in range(niters + 1):\n",
    "            \n",
    "            output = model(current_input)\n",
    "            predictions = output[0, -1, -2:]\n",
    "\n",
    "            print(output)\n",
    "            \n",
    "            outputs[i, :] = predictions\n",
    "\n",
    "            break\n",
    "            \n",
    "            if i == niters:\n",
    "                break\n",
    "\n",
    "            pos = i * 2 + ff_len\n",
    "            \n",
    "            current_input[0, pos] = predictions[0].reshape(1, 1)\n",
    "            current_input[0, pos + 1] = predictions[1].reshape(1, 1)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "69b0099a-759e-48e6-b1e5-dafec296ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    data = data.cpu().numpy()\n",
    "\n",
    "    r = label_r_scaler.inverse_transform(data[:, 0].reshape(1, -1)).reshape(-1, 1)\n",
    "    i = label_i_scaler.inverse_transform(data[:, 1].reshape(1, -1)).reshape(-1, 1)\n",
    "            \n",
    "    return np.concatenate((r, i), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ea04c086-2a30-4939-8b0f-8f2a453338e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(true_values, predictions, epsilon=1e-8):\n",
    "    true_values = np.array(true_values)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    mape = np.mean(np.abs((true_values - predictions) / (true_values + epsilon))) * 100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b0024484-9883-459c-bfe4-bf5bd07e111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader.dataset[i];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "5a32d364-08a1-4e3c-8b47-d93f79db3b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6405e+00],\n",
      "        [-2.9219e-01],\n",
      "        [-1.9585e-01],\n",
      "        [-2.6310e-01],\n",
      "        [-1.3628e+00],\n",
      "        [ 8.0899e-02],\n",
      "        [ 8.5878e-01],\n",
      "        [ 1.5760e-01],\n",
      "        [ 5.9940e-01],\n",
      "        [ 6.6298e-02],\n",
      "        [ 7.8556e-01],\n",
      "        [ 2.5548e-02],\n",
      "        [ 8.2903e-01],\n",
      "        [ 3.3141e-03],\n",
      "        [ 8.0128e-01],\n",
      "        [-1.0240e-02],\n",
      "        [ 7.2251e-01],\n",
      "        [-1.8943e-02],\n",
      "        [ 6.0766e-01],\n",
      "        [-2.4607e-02],\n",
      "        [ 4.6878e-01],\n",
      "        [-2.8217e-02],\n",
      "        [ 3.1550e-01],\n",
      "        [-3.0367e-02],\n",
      "        [ 1.5529e-01],\n",
      "        [-3.1446e-02],\n",
      "        [-6.1983e-03],\n",
      "        [-3.1726e-02],\n",
      "        [-1.6482e-01],\n",
      "        [-3.1406e-02],\n",
      "        [-3.1765e-01],\n",
      "        [-3.0636e-02],\n",
      "        [-4.6276e-01],\n",
      "        [-2.8191e-02],\n",
      "        [-7.2559e-01],\n",
      "        [-2.5055e-02],\n",
      "        [-9.4980e-01],\n",
      "        [-2.1640e-02],\n",
      "        [-1.1370e+00],\n",
      "        [-1.6517e-02],\n",
      "        [-1.3573e+00],\n",
      "        [-1.1758e-02],\n",
      "        [-1.5189e+00],\n",
      "        [-6.2435e-03],\n",
      "        [-1.6678e+00],\n",
      "        [ 2.4502e-04],\n",
      "        [-1.7989e+00],\n",
      "        [ 5.6421e-03],\n",
      "        [-1.8736e+00],\n",
      "        [ 1.0264e-02],\n",
      "        [-1.9113e+00],\n",
      "        [ 1.4272e-02],\n",
      "        [-1.9204e+00],\n",
      "        [ 1.7361e-02],\n",
      "        [-1.9078e+00],\n",
      "        [ 1.9833e-02],\n",
      "        [-1.8799e+00],\n",
      "        [ 2.1404e-02],\n",
      "        [-1.8495e+00]], device='cuda:0')\n",
      "tensor([[[ 1.1883e-01,  5.2311e-01],\n",
      "         [ 4.2824e-01,  5.6966e-01],\n",
      "         [ 9.1109e-02,  5.9315e-01],\n",
      "         [ 1.6492e-01,  5.7762e-01],\n",
      "         [ 3.5261e-01,  5.0573e-01],\n",
      "         [ 9.2139e-02,  5.0770e-01],\n",
      "         [ 2.0841e-01,  5.4133e-01],\n",
      "         [-7.1600e-02, -1.8648e-01],\n",
      "         [-1.4880e-01,  3.8390e-02],\n",
      "         [-5.0228e-02, -1.0465e-01],\n",
      "         [-7.6854e-02, -1.1852e-01],\n",
      "         [-3.0909e-02, -9.2373e-02],\n",
      "         [-5.3865e-02, -1.8735e-01],\n",
      "         [-1.4168e-02, -8.6743e-02],\n",
      "         [-4.4408e-02, -1.9961e-01],\n",
      "         [-9.9738e-04, -8.6605e-02],\n",
      "         [-3.5986e-02, -1.8734e-01],\n",
      "         [ 5.3231e-03, -9.3374e-02],\n",
      "         [-3.1256e-02, -1.6759e-01],\n",
      "         [ 6.2697e-03, -9.5941e-02],\n",
      "         [-2.8014e-02, -1.4607e-01],\n",
      "         [ 9.7282e-03, -9.8211e-02],\n",
      "         [-2.1779e-02, -1.2363e-01],\n",
      "         [ 1.2735e-02, -9.9733e-02],\n",
      "         [-1.8014e-02, -1.0364e-01],\n",
      "         [ 2.0225e-02, -1.0316e-01],\n",
      "         [-1.4363e-02, -8.9833e-02],\n",
      "         [ 1.6765e-02, -1.0502e-01],\n",
      "         [-1.1173e-02, -7.6502e-02],\n",
      "         [ 2.7179e-02, -1.0311e-01],\n",
      "         [-8.2460e-03, -6.6251e-02],\n",
      "         [ 3.2648e-02, -9.6513e-02],\n",
      "         [-1.0002e-02, -1.4001e-01],\n",
      "         [ 3.3711e-02, -8.9275e-02],\n",
      "         [-8.6840e-03, -1.0340e-01],\n",
      "         [ 4.0833e-02, -7.9522e-02],\n",
      "         [-5.8757e-03, -7.9958e-02],\n",
      "         [ 2.8996e-02, -7.0421e-02],\n",
      "         [-4.5625e-03, -1.0646e-01],\n",
      "         [ 3.4056e-02, -6.9126e-02],\n",
      "         [-3.0993e-03, -7.8419e-02],\n",
      "         [ 2.0209e-02, -6.0562e-02],\n",
      "         [-8.9975e-04, -8.8173e-02],\n",
      "         [ 8.8165e-03, -5.9229e-02],\n",
      "         [-1.8261e-03, -9.8599e-02],\n",
      "         [ 1.0188e-02, -4.2765e-02],\n",
      "         [ 2.3831e-04, -8.1297e-02],\n",
      "         [ 1.4820e-02,  1.6569e-02],\n",
      "         [ 1.0884e-03, -8.0084e-02],\n",
      "         [ 1.2412e-02,  5.5542e-02],\n",
      "         [ 6.6581e-04, -7.8295e-02],\n",
      "         [ 1.7407e-02,  8.9709e-02],\n",
      "         [ 9.0827e-04, -7.5007e-02],\n",
      "         [ 1.4372e-02,  1.1865e-01],\n",
      "         [ 1.1464e-03, -7.4560e-02],\n",
      "         [ 8.3319e-03, -5.4218e-01],\n",
      "         [ 1.2359e-03, -7.1710e-02],\n",
      "         [-5.4177e-03, -7.0336e-01],\n",
      "         [ 3.4196e-03, -6.9270e-02]]], device='cuda:0')\n",
      "tensor([[ 1.5760e-01,  5.9940e-01],\n",
      "        [ 6.6298e-02,  7.8556e-01],\n",
      "        [ 2.5548e-02,  8.2903e-01],\n",
      "        [ 3.3141e-03,  8.0128e-01],\n",
      "        [-1.0240e-02,  7.2251e-01],\n",
      "        [-1.8943e-02,  6.0766e-01],\n",
      "        [-2.4607e-02,  4.6878e-01],\n",
      "        [-2.8217e-02,  3.1550e-01],\n",
      "        [-3.0367e-02,  1.5529e-01],\n",
      "        [-3.1446e-02, -6.1983e-03],\n",
      "        [-3.1726e-02, -1.6482e-01],\n",
      "        [-3.1406e-02, -3.1765e-01],\n",
      "        [-3.0636e-02, -4.6276e-01],\n",
      "        [-2.8191e-02, -7.2559e-01],\n",
      "        [-2.5055e-02, -9.4980e-01],\n",
      "        [-2.1640e-02, -1.1370e+00],\n",
      "        [-1.6517e-02, -1.3573e+00],\n",
      "        [-1.1758e-02, -1.5189e+00],\n",
      "        [-6.2435e-03, -1.6678e+00],\n",
      "        [ 2.4502e-04, -1.7989e+00],\n",
      "        [ 5.6421e-03, -1.8736e+00],\n",
      "        [ 1.0264e-02, -1.9113e+00],\n",
      "        [ 1.4272e-02, -1.9204e+00],\n",
      "        [ 1.7361e-02, -1.9078e+00],\n",
      "        [ 1.9833e-02, -1.8799e+00],\n",
      "        [ 2.1404e-02, -1.8495e+00],\n",
      "        [ 2.2185e-02, -1.8288e+00]])\n",
      "tensor([[ 0.0034, -0.0693],\n",
      "        [ 0.0036, -0.0692],\n",
      "        [ 0.0040, -0.0691],\n",
      "        [ 0.0045, -0.0689],\n",
      "        [ 0.0051, -0.0688],\n",
      "        [ 0.0058, -0.0687],\n",
      "        [ 0.0065, -0.0685],\n",
      "        [ 0.0072, -0.0684],\n",
      "        [ 0.0079, -0.0682],\n",
      "        [ 0.0086, -0.0680],\n",
      "        [ 0.0093, -0.0678],\n",
      "        [ 0.0100, -0.0675],\n",
      "        [ 0.0106, -0.0673],\n",
      "        [ 0.0112, -0.0671],\n",
      "        [ 0.0117, -0.0670],\n",
      "        [ 0.0122, -0.0667],\n",
      "        [ 0.0127, -0.0665],\n",
      "        [ 0.0131, -0.0663],\n",
      "        [ 0.0136, -0.0661],\n",
      "        [ 0.0140, -0.0659],\n",
      "        [ 0.0144, -0.0656],\n",
      "        [ 0.0148, -0.0654],\n",
      "        [ 0.0152, -0.0652],\n",
      "        [ 0.0156, -0.0650],\n",
      "        [ 0.0160, -0.0647],\n",
      "        [ 0.0162, -0.0643],\n",
      "        [ 0.0172, -0.1239]], device='cuda:0')\n",
      "[[ 0.37865344 -0.00128612]\n",
      " [ 0.3786974  -0.00383589]\n",
      " [ 0.37878466 -0.00631966]\n",
      " [ 0.37891376 -0.00869781]\n",
      " [ 0.3790826  -0.01093667]\n",
      " [ 0.37928805 -0.01300983]\n",
      " [ 0.3795264  -0.01489872]\n",
      " [ 0.37979326 -0.01659244]\n",
      " [ 0.3800837  -0.01808707]\n",
      " [ 0.38039285 -0.01938467]\n",
      " [ 0.3807156  -0.02049208]\n",
      " [ 0.3810473  -0.02141969]\n",
      " [ 0.38138363 -0.02218032]\n",
      " [ 0.38205513 -0.02325832]\n",
      " [ 0.38270587 -0.02384411]\n",
      " [ 0.38331988 -0.02404942]\n",
      " [ 0.38415408 -0.02385065]\n",
      " [ 0.38487703 -0.02326168]\n",
      " [ 0.38567767 -0.02215908]\n",
      " [ 0.3865877  -0.02028147]\n",
      " [ 0.38732794 -0.01816486]\n",
      " [ 0.38795444 -0.01581799]\n",
      " [ 0.3884952  -0.01318164]\n",
      " [ 0.3889119  -0.01049864]\n",
      " [ 0.38924685 -0.00750482]\n",
      " [ 0.38946122 -0.00453163]\n",
      " [ 0.38956836 -0.00151019]]\n",
      "tensor([[ 0.0034, -0.0693],\n",
      "        [ 0.0036, -0.0692],\n",
      "        [ 0.0040, -0.0691],\n",
      "        [ 0.0045, -0.0689],\n",
      "        [ 0.0051, -0.0688],\n",
      "        [ 0.0058, -0.0687],\n",
      "        [ 0.0065, -0.0685],\n",
      "        [ 0.0072, -0.0684],\n",
      "        [ 0.0079, -0.0682],\n",
      "        [ 0.0086, -0.0680],\n",
      "        [ 0.0093, -0.0678],\n",
      "        [ 0.0100, -0.0675],\n",
      "        [ 0.0106, -0.0673],\n",
      "        [ 0.0112, -0.0671],\n",
      "        [ 0.0117, -0.0670],\n",
      "        [ 0.0122, -0.0667],\n",
      "        [ 0.0127, -0.0665],\n",
      "        [ 0.0131, -0.0663],\n",
      "        [ 0.0136, -0.0661],\n",
      "        [ 0.0140, -0.0659],\n",
      "        [ 0.0144, -0.0656],\n",
      "        [ 0.0148, -0.0654],\n",
      "        [ 0.0152, -0.0652],\n",
      "        [ 0.0156, -0.0650],\n",
      "        [ 0.0160, -0.0647],\n",
      "        [ 0.0162, -0.0643],\n",
      "        [ 0.0172, -0.1239]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "134.5969319343567"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 100 #train_loader.dataset.dataset.n_samples \n",
    "sequence_length = 59\n",
    "ff_len = len(fixed_features)\n",
    "dim = 1\n",
    "\n",
    "mapes = []\n",
    "\n",
    "for i in range(1):\n",
    "    input, target, idx = dataset.__getitem__((i + 1) * 26)\n",
    "\n",
    "    print(input)\n",
    "    \n",
    "    targets = torch.zeros(27, 2)\n",
    "    targets[:-1] = input[ff_len:].reshape(26, 2)\n",
    "    targets[-1:] = target[-1]\n",
    "    \n",
    "\n",
    "    outputs = sample_from_model(model, input, idx, sequence_length, ff_len, dim, device)\n",
    "\n",
    "    print(targets)\n",
    "    print(output)\n",
    "    \n",
    "    targets = convert(targets)\n",
    "    outputs = convert(outputs)\n",
    "    \n",
    "    print(targets)\n",
    "    print(output)\n",
    "    \n",
    "    mapes.append(calculate_mape(targets, outputs))\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(i+1)\n",
    "\n",
    "np.mean(mapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f98c960f-1bbe-44da-8d37-f26fae79bd6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (59) must match the existing size (0) at non-singleton dimension 1.  Target sizes: [0, 59].  Tensor sizes: [0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[301], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m val_loader\u001b[38;5;241m.\u001b[39mdataset[idx][\u001b[38;5;241m0\u001b[39m][fixed_labels_len]\n\u001b[1;32m---> 15\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43msample_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_features_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_labels_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     target \u001b[38;5;241m=\u001b[39m convert(val_loader\u001b[38;5;241m.\u001b[39mdataset[idx][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     18\u001b[0m     output \u001b[38;5;241m=\u001b[39m convert(output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[1;32mIn[294], line 8\u001b[0m, in \u001b[0;36msample_from_model\u001b[1;34m(model, input, idx, sequence_length, ff_len, dim, device)\u001b[0m\n\u001b[0;32m      5\u001b[0m fixed_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[:ff_len]\n\u001b[0;32m      7\u001b[0m initial_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, sequence_length, dim)\n\u001b[1;32m----> 8\u001b[0m \u001b[43minitial_input\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mff_len\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m fixed_features\n\u001b[0;32m      9\u001b[0m current_input \u001b[38;5;241m=\u001b[39m initial_input\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(niters \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, device \u001b[38;5;241m=\u001b[39m device)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (59) must match the existing size (0) at non-singleton dimension 1.  Target sizes: [0, 59].  Tensor sizes: [0]"
     ]
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "sequence_length = 27\n",
    "fixed_features_len = len(fixed_features)\n",
    "max_features = fixed_features_len + len(labels) - 2\n",
    "\n",
    "total_mapes = []\n",
    "\n",
    "for j in range(sequence_length):\n",
    "    fixed_labels_len = j\n",
    "    \n",
    "    mapes = []\n",
    "    \n",
    "    for idx in range(n_samples):\n",
    "        input = val_loader.dataset[idx][0][fixed_labels_len]\n",
    "        output = sample_from_model(model, input, sequence_length, fixed_features_len, fixed_labels_len, max_features, device)\n",
    "        \n",
    "        target = convert(val_loader.dataset[idx][1].reshape(-1))\n",
    "        output = convert(output.reshape(-1))\n",
    "        \n",
    "        mapes.append(calculate_mape(target, output))\n",
    "    \n",
    "        if (idx+1) % 1000 == 0:\n",
    "            print(idx+1)\n",
    "\n",
    "    total_mapes.append(np.mean(mapes))\n",
    "\n",
    "print(total_mapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bb57db-9397-47a9-8ebe-cba82a785c6d",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dbad0476-9d99-4d5e-84ce-77fa6a2f5d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576,\n",
       "          0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576,\n",
       "          0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576, 0.1576]]),\n",
       " tensor([[0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994,\n",
       "          0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994,\n",
       "          0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994, 0.5994]]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat, label, i = dataset.__getitem__(1)\n",
    "real = label[i].reshape(-1, 1).repeat(27, 1)[::2].reshape(1, -1).cpu()\n",
    "img = label[i].reshape(-1, 1).repeat(27, 1)[1::2].reshape(1, -1).cpu()\n",
    "real, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "235c360f-9c91-401d-bc39-11dcbadf832d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(i - (len(fixed_features) - 1)) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f229a482-9087-4ace-b5b3-742cd5d97e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.37865343]), array([-0.00128612]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_t = label_r_scaler.inverse_transform(real).reshape(-1, 1)\n",
    "img_t = label_i_scaler.inverse_transform(img).reshape(-1, 1)\n",
    "real_t[(i - (len(fixed_features) - 1)) // 2], img_t[(i - (len(fixed_features) - 1)) // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "97a54408-3237-42a3-8697-34dda903070c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReSf1</th>\n",
       "      <th>ImSf1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.378653</td>\n",
       "      <td>-0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.445733</td>\n",
       "      <td>-0.059607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.622064</td>\n",
       "      <td>-0.039583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.635753</td>\n",
       "      <td>-0.013387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.334830</td>\n",
       "      <td>-0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.375442</td>\n",
       "      <td>-0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.419402</td>\n",
       "      <td>-0.046064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.456471</td>\n",
       "      <td>-0.002609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.559925</td>\n",
       "      <td>-0.058278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.364483</td>\n",
       "      <td>-0.004486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ReSf1     ImSf1\n",
       "0     0.378653 -0.001286\n",
       "1     0.445733 -0.059607\n",
       "2     0.622064 -0.039583\n",
       "3     0.635753 -0.013387\n",
       "4     0.334830 -0.000671\n",
       "...        ...       ...\n",
       "9995  0.375442 -0.002151\n",
       "9996  0.419402 -0.046064\n",
       "9997  0.456471 -0.002609\n",
       "9998  0.559925 -0.058278\n",
       "9999  0.364483 -0.004486\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['ReSf1', 'ImSf1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eac55e45-3778-41fc-afc0-473ee5ac8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_df = train_test_split(df, test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51adc2a3-46f6-4ee3-9472-165ecb7f7c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReSf1</th>\n",
       "      <th>ReSf3</th>\n",
       "      <th>ReSf5</th>\n",
       "      <th>ReSf7</th>\n",
       "      <th>ReSf9</th>\n",
       "      <th>ReSf11</th>\n",
       "      <th>ReSf13</th>\n",
       "      <th>ReSf15</th>\n",
       "      <th>ReSf17</th>\n",
       "      <th>ReSf19</th>\n",
       "      <th>...</th>\n",
       "      <th>ReSf49</th>\n",
       "      <th>ReSf57</th>\n",
       "      <th>ReSf69</th>\n",
       "      <th>ReSf83</th>\n",
       "      <th>ReSf101</th>\n",
       "      <th>ReSf127</th>\n",
       "      <th>ReSf165</th>\n",
       "      <th>ReSf237</th>\n",
       "      <th>ReSf399</th>\n",
       "      <th>ReSf1207</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>0.283896</td>\n",
       "      <td>0.283963</td>\n",
       "      <td>0.284096</td>\n",
       "      <td>0.284291</td>\n",
       "      <td>0.284544</td>\n",
       "      <td>0.284850</td>\n",
       "      <td>0.285203</td>\n",
       "      <td>0.285597</td>\n",
       "      <td>0.286025</td>\n",
       "      <td>0.286482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293903</td>\n",
       "      <td>0.295546</td>\n",
       "      <td>0.297626</td>\n",
       "      <td>0.299535</td>\n",
       "      <td>0.301349</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>0.304595</td>\n",
       "      <td>0.305908</td>\n",
       "      <td>0.306809</td>\n",
       "      <td>0.307278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>0.395039</td>\n",
       "      <td>0.396192</td>\n",
       "      <td>0.397776</td>\n",
       "      <td>0.399200</td>\n",
       "      <td>0.400289</td>\n",
       "      <td>0.401078</td>\n",
       "      <td>0.401643</td>\n",
       "      <td>0.402053</td>\n",
       "      <td>0.402356</td>\n",
       "      <td>0.402583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>0.403519</td>\n",
       "      <td>0.403561</td>\n",
       "      <td>0.403589</td>\n",
       "      <td>0.403609</td>\n",
       "      <td>0.403625</td>\n",
       "      <td>0.403636</td>\n",
       "      <td>0.403644</td>\n",
       "      <td>0.403649</td>\n",
       "      <td>0.403652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>0.231242</td>\n",
       "      <td>0.323789</td>\n",
       "      <td>0.336674</td>\n",
       "      <td>0.340689</td>\n",
       "      <td>0.342421</td>\n",
       "      <td>0.343318</td>\n",
       "      <td>0.343841</td>\n",
       "      <td>0.344172</td>\n",
       "      <td>0.344394</td>\n",
       "      <td>0.344550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345086</td>\n",
       "      <td>0.345111</td>\n",
       "      <td>0.345133</td>\n",
       "      <td>0.345148</td>\n",
       "      <td>0.345159</td>\n",
       "      <td>0.345167</td>\n",
       "      <td>0.345173</td>\n",
       "      <td>0.345177</td>\n",
       "      <td>0.345180</td>\n",
       "      <td>0.345181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>0.227485</td>\n",
       "      <td>0.265939</td>\n",
       "      <td>0.281392</td>\n",
       "      <td>0.288057</td>\n",
       "      <td>0.291425</td>\n",
       "      <td>0.293341</td>\n",
       "      <td>0.294527</td>\n",
       "      <td>0.295309</td>\n",
       "      <td>0.295849</td>\n",
       "      <td>0.296237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297627</td>\n",
       "      <td>0.297694</td>\n",
       "      <td>0.297754</td>\n",
       "      <td>0.297794</td>\n",
       "      <td>0.297824</td>\n",
       "      <td>0.297846</td>\n",
       "      <td>0.297862</td>\n",
       "      <td>0.297873</td>\n",
       "      <td>0.297881</td>\n",
       "      <td>0.297884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.569755</td>\n",
       "      <td>0.569608</td>\n",
       "      <td>0.569401</td>\n",
       "      <td>0.569149</td>\n",
       "      <td>0.568867</td>\n",
       "      <td>0.568570</td>\n",
       "      <td>0.568270</td>\n",
       "      <td>0.567977</td>\n",
       "      <td>0.567699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565689</td>\n",
       "      <td>0.565535</td>\n",
       "      <td>0.565399</td>\n",
       "      <td>0.565312</td>\n",
       "      <td>0.565252</td>\n",
       "      <td>0.565209</td>\n",
       "      <td>0.565181</td>\n",
       "      <td>0.565161</td>\n",
       "      <td>0.565150</td>\n",
       "      <td>0.565144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>0.385395</td>\n",
       "      <td>0.393142</td>\n",
       "      <td>0.401404</td>\n",
       "      <td>0.405372</td>\n",
       "      <td>0.407445</td>\n",
       "      <td>0.408634</td>\n",
       "      <td>0.409369</td>\n",
       "      <td>0.409852</td>\n",
       "      <td>0.410184</td>\n",
       "      <td>0.410423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411269</td>\n",
       "      <td>0.411310</td>\n",
       "      <td>0.411346</td>\n",
       "      <td>0.411371</td>\n",
       "      <td>0.411388</td>\n",
       "      <td>0.411402</td>\n",
       "      <td>0.411411</td>\n",
       "      <td>0.411418</td>\n",
       "      <td>0.411423</td>\n",
       "      <td>0.411425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>0.299184</td>\n",
       "      <td>0.311765</td>\n",
       "      <td>0.318668</td>\n",
       "      <td>0.322133</td>\n",
       "      <td>0.323979</td>\n",
       "      <td>0.325045</td>\n",
       "      <td>0.325705</td>\n",
       "      <td>0.326140</td>\n",
       "      <td>0.326439</td>\n",
       "      <td>0.326654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327415</td>\n",
       "      <td>0.327452</td>\n",
       "      <td>0.327484</td>\n",
       "      <td>0.327506</td>\n",
       "      <td>0.327522</td>\n",
       "      <td>0.327534</td>\n",
       "      <td>0.327543</td>\n",
       "      <td>0.327549</td>\n",
       "      <td>0.327553</td>\n",
       "      <td>0.327555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>0.174371</td>\n",
       "      <td>0.210826</td>\n",
       "      <td>0.224599</td>\n",
       "      <td>0.230770</td>\n",
       "      <td>0.233986</td>\n",
       "      <td>0.235840</td>\n",
       "      <td>0.236993</td>\n",
       "      <td>0.237753</td>\n",
       "      <td>0.238279</td>\n",
       "      <td>0.238657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240005</td>\n",
       "      <td>0.240069</td>\n",
       "      <td>0.240128</td>\n",
       "      <td>0.240167</td>\n",
       "      <td>0.240195</td>\n",
       "      <td>0.240216</td>\n",
       "      <td>0.240232</td>\n",
       "      <td>0.240243</td>\n",
       "      <td>0.240250</td>\n",
       "      <td>0.240253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>0.259463</td>\n",
       "      <td>0.271048</td>\n",
       "      <td>0.275675</td>\n",
       "      <td>0.277917</td>\n",
       "      <td>0.279126</td>\n",
       "      <td>0.279831</td>\n",
       "      <td>0.280271</td>\n",
       "      <td>0.280561</td>\n",
       "      <td>0.280762</td>\n",
       "      <td>0.280905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281415</td>\n",
       "      <td>0.281440</td>\n",
       "      <td>0.281462</td>\n",
       "      <td>0.281476</td>\n",
       "      <td>0.281487</td>\n",
       "      <td>0.281495</td>\n",
       "      <td>0.281501</td>\n",
       "      <td>0.281505</td>\n",
       "      <td>0.281508</td>\n",
       "      <td>0.281509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7713</th>\n",
       "      <td>0.238240</td>\n",
       "      <td>0.243108</td>\n",
       "      <td>0.247942</td>\n",
       "      <td>0.251306</td>\n",
       "      <td>0.253518</td>\n",
       "      <td>0.254999</td>\n",
       "      <td>0.256022</td>\n",
       "      <td>0.256751</td>\n",
       "      <td>0.257283</td>\n",
       "      <td>0.257682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259234</td>\n",
       "      <td>0.259314</td>\n",
       "      <td>0.259386</td>\n",
       "      <td>0.259434</td>\n",
       "      <td>0.259470</td>\n",
       "      <td>0.259497</td>\n",
       "      <td>0.259516</td>\n",
       "      <td>0.259530</td>\n",
       "      <td>0.259539</td>\n",
       "      <td>0.259543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ReSf1     ReSf3     ReSf5     ReSf7     ReSf9    ReSf11    ReSf13  \\\n",
       "6252  0.283896  0.283963  0.284096  0.284291  0.284544  0.284850  0.285203   \n",
       "4684  0.395039  0.396192  0.397776  0.399200  0.400289  0.401078  0.401643   \n",
       "1731  0.231242  0.323789  0.336674  0.340689  0.342421  0.343318  0.343841   \n",
       "4742  0.227485  0.265939  0.281392  0.288057  0.291425  0.293341  0.294527   \n",
       "4521  0.569832  0.569755  0.569608  0.569401  0.569149  0.568867  0.568570   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3921  0.385395  0.393142  0.401404  0.405372  0.407445  0.408634  0.409369   \n",
       "6685  0.299184  0.311765  0.318668  0.322133  0.323979  0.325045  0.325705   \n",
       "3194  0.174371  0.210826  0.224599  0.230770  0.233986  0.235840  0.236993   \n",
       "1941  0.259463  0.271048  0.275675  0.277917  0.279126  0.279831  0.280271   \n",
       "7713  0.238240  0.243108  0.247942  0.251306  0.253518  0.254999  0.256022   \n",
       "\n",
       "        ReSf15    ReSf17    ReSf19  ...    ReSf49    ReSf57    ReSf69  \\\n",
       "6252  0.285597  0.286025  0.286482  ...  0.293903  0.295546  0.297626   \n",
       "4684  0.402053  0.402356  0.402583  ...  0.403473  0.403519  0.403561   \n",
       "1731  0.344172  0.344394  0.344550  ...  0.345086  0.345111  0.345133   \n",
       "4742  0.295309  0.295849  0.296237  ...  0.297627  0.297694  0.297754   \n",
       "4521  0.568270  0.567977  0.567699  ...  0.565689  0.565535  0.565399   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3921  0.409852  0.410184  0.410423  ...  0.411269  0.411310  0.411346   \n",
       "6685  0.326140  0.326439  0.326654  ...  0.327415  0.327452  0.327484   \n",
       "3194  0.237753  0.238279  0.238657  ...  0.240005  0.240069  0.240128   \n",
       "1941  0.280561  0.280762  0.280905  ...  0.281415  0.281440  0.281462   \n",
       "7713  0.256751  0.257283  0.257682  ...  0.259234  0.259314  0.259386   \n",
       "\n",
       "        ReSf83   ReSf101   ReSf127   ReSf165   ReSf237   ReSf399  ReSf1207  \n",
       "6252  0.299535  0.301349  0.303100  0.304595  0.305908  0.306809  0.307278  \n",
       "4684  0.403589  0.403609  0.403625  0.403636  0.403644  0.403649  0.403652  \n",
       "1731  0.345148  0.345159  0.345167  0.345173  0.345177  0.345180  0.345181  \n",
       "4742  0.297794  0.297824  0.297846  0.297862  0.297873  0.297881  0.297884  \n",
       "4521  0.565312  0.565252  0.565209  0.565181  0.565161  0.565150  0.565144  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3921  0.411371  0.411388  0.411402  0.411411  0.411418  0.411423  0.411425  \n",
       "6685  0.327506  0.327522  0.327534  0.327543  0.327549  0.327553  0.327555  \n",
       "3194  0.240167  0.240195  0.240216  0.240232  0.240243  0.240250  0.240253  \n",
       "1941  0.281476  0.281487  0.281495  0.281501  0.281505  0.281508  0.281509  \n",
       "7713  0.259434  0.259470  0.259497  0.259516  0.259530  0.259539  0.259543  \n",
       "\n",
       "[1000 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = train_df[labels]\n",
    "df_labels[df_labels.columns[::2]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
