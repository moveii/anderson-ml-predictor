{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8719881-b067-4348-b595-a5353298c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca748c2b-4249-41c3-8efa-a86ca9872139",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ac45631-459d-4fa3-9f8b-211e80ca1226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b32cbd-59d6-4dc6-9f60-b550e4de4eab",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7459a0f-4a62-48c6-9539-27276524679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImpurityDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, fixed_features, labels, feature_scaler=None, label_r_scaler=None, label_i_scaler=None, device=None):\n",
    "        assert len(labels) % 2 == 0\n",
    "        \n",
    "        self.fixed_features = fixed_features\n",
    "        self.labels = labels\n",
    "        self.n_samples = len(dataframe)\n",
    "        \n",
    "        self.output_length = 2\n",
    "        self.input_length = len(fixed_features) + len(labels) - self.output_length\n",
    "        self.sequence_length = len(labels) // self.output_length\n",
    "\n",
    "        df_features = dataframe[fixed_features]\n",
    "        df_labels = dataframe[labels]\n",
    "        \n",
    "        if feature_scaler is not None and label_r_scaler is not None and label_i_scaler is not None:\n",
    "            xs = feature_scaler.transform(df_features)\n",
    "            #ys = df_labels.values\n",
    "            \n",
    "            ys_r = label_r_scaler.transform(df_labels[df_labels.columns[::2]])\n",
    "            ys_i = label_i_scaler.transform(df_labels[df_labels.columns[1::2]])\n",
    "            \n",
    "            ys = np.empty((ys_r.shape[0], ys_r.shape[1] * 2), dtype=ys_r.dtype)\n",
    "            ys[:, ::2] = ys_r  # fill even indices with real parts\n",
    "            ys[:, 1::2] = ys_i  # fill odd indices with imaginary parts\n",
    "        else:\n",
    "            xs = df_features.values\n",
    "            ys = df_labels.values\n",
    "\n",
    "        feature_data = np.zeros((self.n_samples, self.sequence_length, self.input_length))\n",
    "        label_data = np.zeros((self.n_samples, self.sequence_length, self.output_length))\n",
    "        \n",
    "        for i in range(self.n_samples):\n",
    "            for j in range(self.sequence_length):\n",
    "                xi = xs[i]\n",
    "                xj = ys[i][0:j*2]\n",
    "                y = ys[i][j*2:j*2+2]\n",
    "        \n",
    "                features = np.concatenate([xi, xj], axis=0)\n",
    "                pad_width = self.input_length - len(features)\n",
    "                feature_data[i, j, :] = np.pad(features, (0, pad_width))\n",
    "                label_data[i, j, :] = y\n",
    "\n",
    "        self.feature_data = torch.tensor(feature_data, dtype=torch.float).to(device)\n",
    "        self.label_data = torch.tensor(label_data, dtype=torch.float).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.feature_data[idx], self.label_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4745dbe-e866-40ee-8014-320fb6de09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scalers(dataframe, fixed_features, labels, test_size=0.1, random_state=None):\n",
    "    train_df, _ = train_test_split(dataframe, test_size=test_size, random_state=random_state)\n",
    "    df_features = train_df[fixed_features]\n",
    "    df_labels = train_df[labels]\n",
    "    \n",
    "    feature_scaler = StandardScaler()\n",
    "    label_r_scaler = StandardScaler()\n",
    "    label_i_scaler = StandardScaler()\n",
    "\n",
    "    feature_scaler.fit(df_features)\n",
    "    label_r_scaler.fit(df_labels[df_labels.columns[::2]]) # get only real columns\n",
    "    label_i_scaler.fit(df_labels[df_labels.columns[1::2]]) # get only imaginary columns\n",
    "\n",
    "    return feature_scaler, label_r_scaler, label_i_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1bb7fbd-7c0a-495d-bc24-772b235a90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/20230825_144318_10k_EVDoubExp-TExp-wmax5-sparse-hyb_with_perturbation.csv'\n",
    "\n",
    "#fixed_features = ['beta', 'U', 'Eimp', 'E1', 'E2', 'E3', 'V1', 'V2', 'V3']\n",
    "fixed_features = ['beta', 'E1', 'E2', 'E3', 'V1', 'V2', 'V3']\n",
    "labels = ['ReSf1', 'ImSf1', 'ReSf3', 'ImSf3', 'ReSf5', 'ImSf5', 'ReSf7', 'ImSf7', 'ReSf9', 'ImSf9', 'ReSf11', 'ImSf11', 'ReSf13', 'ImSf13', 'ReSf15', 'ImSf15', 'ReSf17', 'ImSf17', 'ReSf19', 'ImSf19', 'ReSf21', 'ImSf21', 'ReSf23', 'ImSf23', 'ReSf25', 'ImSf25', 'ReSf29', 'ImSf29', 'ReSf33', 'ImSf33', 'ReSf37', 'ImSf37', 'ReSf43', 'ImSf43', 'ReSf49', 'ImSf49', 'ReSf57', 'ImSf57', 'ReSf69', 'ImSf69', 'ReSf83', 'ImSf83', 'ReSf101', 'ImSf101', 'ReSf127', 'ImSf127', 'ReSf165', 'ImSf165', 'ReSf237', 'ImSf237', 'ReSf399', 'ImSf399', 'ReSf1207', 'ImSf1207']\n",
    "\n",
    "df = pd.read_csv(file_path, skiprows=4) # we skip the first four lines, because they are just metadata\n",
    "df = df[fixed_features + labels]\n",
    "\n",
    "validation_size = 0.1 # 90% training, 10% for validation\n",
    "\n",
    "feature_scaler, label_r_scaler, label_i_scaler = compute_scalers(df, fixed_features, labels, validation_size, seed) # make sure we use the same seed, otherwise the two splits differ!\n",
    "#dataset = ImpurityDataset(df, fixed_features, labels, device=device)\n",
    "dataset = ImpurityDataset(df, fixed_features, labels, feature_scaler, label_r_scaler, label_i_scaler, device)  \n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, val_indices = train_test_split(indices, test_size=validation_size, random_state=seed)  # make sure we use the same seed, otherwise the two splits differ!\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98f8b9d2-454a-41dd-bd6e-232135263d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6405, -0.2922, -0.1958,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 1.6405, -0.2922, -0.1958,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 1.6405, -0.2922, -0.1958,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 1.6405, -0.2922, -0.1958,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 1.6405, -0.2922, -0.1958,  ..., -1.8799,  0.0000,  0.0000],\n",
       "        [ 1.6405, -0.2922, -0.1958,  ..., -1.8799,  0.0214, -1.8495]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23694fa-f39d-48b1-9a50-d815762d86ea",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2581363e-4b96-4ef8-bf92-5f633aca6dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodingL(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=27):\n",
    "        super(PositionalEncodingL, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.positional_embedding = nn.Parameter(torch.zeros(max_len, d_model))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, d_model]\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        \n",
    "        # Use the first 'seq_len' positions from the positional_embedding\n",
    "        # Expand the positional embeddings to match the batch size and add them to the input\n",
    "        position_encoded = self.positional_embedding[:, :].unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        x = x + position_encoded\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2eee253d-b790-4860-bab8-305eb0ca7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodingF(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=27):\n",
    "        super(PositionalEncodingF, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c648bc1c-a7b4-4b82-bf63-e06dd0967f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    input_dim: int\n",
    "    output_dim: int\n",
    "    sequence_length: int\n",
    "    \n",
    "    d_model: int\n",
    "    nhead: int\n",
    "    num_layers: int\n",
    "    dim_feedforward: int\n",
    "    \n",
    "    dropout: float\n",
    "    activation: str\n",
    "    bias: bool\n",
    "\n",
    "class AutoregressiveTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, config, device):\n",
    "        super(AutoregressiveTransformer, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        #self.input_projection = nn.Linear(config.input_dim, config.d_model)\n",
    "        self.input_projection = nn.Linear(config.input_dim, config.d_model)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncodingL(config.d_model, dropout=config.dropout, max_len=config.sequence_length)\n",
    "        \n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=config.d_model, \n",
    "            nhead=config.nhead, \n",
    "            dim_feedforward=config.dim_feedforward, \n",
    "            dropout=config.dropout,\n",
    "            activation=config.activation, \n",
    "            batch_first=True, \n",
    "            norm_first=True, \n",
    "            bias=config.bias\n",
    "        )\n",
    "        \n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=config.num_layers)\n",
    "        \n",
    "        self.output_layer = nn.Linear(config.d_model, config.output_dim)\n",
    "        \n",
    "        self.att_mask = self.generate_mask(config.sequence_length, device)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.input_projection(x)        \n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        output = self.transformer_decoder(x, x, tgt_mask=self.att_mask)\n",
    "        output = self.output_layer(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def generate_mask(self, sequence_length, device):\n",
    "        mask = torch.zeros((sequence_length, sequence_length), device=device)\n",
    "        mask = torch.triu(mask.fill_(float('-inf')), diagonal=1)\n",
    "            \n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0842f-41f6-420c-b896-4b19f67805c3",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5edc082b-3d45-4afb-95b6-4d2edaa703e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ModelConfig(\n",
    "    input_dim = 59,\n",
    "    output_dim = 2,\n",
    "    sequence_length = 27,\n",
    "    \n",
    "    d_model = 256,\n",
    "    nhead = 4,\n",
    "    num_layers = 2,\n",
    "    dim_feedforward = 256 * 4,\n",
    "    \n",
    "    dropout = 0.1,\n",
    "    activation = 'gelu',\n",
    "    bias = True\n",
    ")\n",
    "\n",
    "model = AutoregressiveTransformer(config, device).to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dec32597-9f94-42fc-a936-be7eb75d331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d324c9b-2a4f-4b65-abcd-7ead8d07e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, targets in val_loader:\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec0284b-7904-4dbc-b42d-69b6d367b8d6",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9067e6b-ea16-42e9-989b-ef6896481deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      4\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model, train_loader, optimizer, criterion, device)\n\u001b[1;32m----> 5\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[42], line 9\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(model, val_loader, criterion, device)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m----> 9\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     12\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[39], line 49\u001b[0m, in \u001b[0;36mAutoregressiveTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_projection(x)        \n\u001b[0;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(x)\n\u001b[1;32m---> 49\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matt_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(output)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:465\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    462\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 465\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    473\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:853\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    851\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x), tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[0;32m    852\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mha_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x), memory, memory_mask, memory_key_padding_mask, memory_is_causal)\n\u001b[1;32m--> 853\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:883\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 883\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout3(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c375fecd-b79b-4a84-b5de-78ea7ed0d24b",
   "metadata": {},
   "source": [
    "### Manual model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f72c8c95-6a90-4792-a74e-302534c87e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mape(model, val_loader, scaler_r, scaler_i, device, epsilon=1e-8):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, targets in val_loader:\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            outputs = torch.tensor(np.array([reverse_tranform_output(o, scaler_r, scaler_i) for o in outputs]))\n",
    "            targets = torch.tensor(np.array([reverse_tranform_output(t, scaler_r, scaler_i) for t in targets]))\n",
    "\n",
    "            ape = torch.abs((targets - outputs) / (targets + epsilon))\n",
    "            mape = torch.mean(ape) * 100\n",
    "                    \n",
    "            total_loss += mape.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa4537b0-7c15-4d74-85bf-65d053516262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_tranform_output(data, scaler_r, scaler_i):\n",
    "    data = data.cpu().numpy()\n",
    "    \n",
    "    r = scaler_r.inverse_transform(data[:, ::2].reshape(1, -1)).reshape(-1, 1)\n",
    "    i = scaler_i.inverse_transform(data[:, 1::2].reshape(1, -1)).reshape(-1, 1)\n",
    "            \n",
    "    return np.concatenate((r, i), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45952c7e-e2d3-4aff-8810-7fd7693e104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n",
      "(27, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.98638406395912"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_mape(model, val_loader, label_r_scaler, label_i_scaler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a0d1d-5db4-417d-8fed-c44ca4256892",
   "metadata": {},
   "source": [
    "### Sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "850f5ca1-bfd3-4716-9088-996e14a68c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(model, input, sequence_length, fixed_feature_len, fixed_labels_len, max_features, device):\n",
    "    model.eval()\n",
    "\n",
    "    fixed_features = input[:fixed_feature_len]\n",
    "    fixed_labels = input[fixed_feature_len:fixed_labels_len*2 + fixed_feature_len]\n",
    "    \n",
    "    assert len(fixed_labels) % 2 == 0\n",
    "    provided_sequences = len(fixed_labels) // 2\n",
    "    \n",
    "    initial_input = torch.zeros(1, sequence_length, max_features)\n",
    "    initial_input[0, 0, :fixed_feature_len] = fixed_features\n",
    "\n",
    "    outputs = torch.zeros(sequence_length, 2, device = device)\n",
    "    \n",
    "    for i in range(1, provided_sequences + 1):\n",
    "        labels = fixed_labels[(i-1)*2:2*i]\n",
    "        initial_input[0, i, :2*i + fixed_feature_len] = initial_input[0, i-1, :2*i + fixed_feature_len]\n",
    "        initial_input[0, i, 2*(i-1) + fixed_feature_len:2*i + fixed_feature_len] = labels\n",
    "        outputs[i-1, :] = labels\n",
    "\n",
    "    current_input = initial_input.to(device)\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i in range(fixed_labels_len + 1, sequence_length + 1):\n",
    "\n",
    "            output = model(current_input)\n",
    "            predictions = output[0, -1, -2:]\n",
    "\n",
    "            outputs[i-1, :] = predictions\n",
    "            \n",
    "            if i == sequence_length:\n",
    "                break\n",
    "            \n",
    "            position_to_insert = i * 2 + fixed_feature_len\n",
    "            current_input[0, i, :position_to_insert-2] = current_input[0, i-1, :position_to_insert-2]\n",
    "            current_input[0, i, position_to_insert-2:position_to_insert] = predictions\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "69b0099a-759e-48e6-b1e5-dafec296ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    data = data.cpu().numpy()\n",
    "            \n",
    "    r = label_r_scaler.inverse_transform(data[::2].reshape(1, -1)).reshape(-1, 1)\n",
    "    i = label_i_scaler.inverse_transform(data[1::2].reshape(1, -1)).reshape(-1, 1)\n",
    "            \n",
    "    return np.concatenate((r, i), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "ea04c086-2a30-4939-8b0f-8f2a453338e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(true_values, predictions, epsilon=1e-8):\n",
    "    true_values = np.array(true_values)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    mape = np.mean(np.abs((true_values - predictions) / (true_values + epsilon))) * 100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "5a32d364-08a1-4e3c-8b47-d93f79db3b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41.89146286994219"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 100 #train_loader.dataset.dataset.n_samples \n",
    "sequence_length = 27\n",
    "fixed_labels_len = 1\n",
    "fixed_features_len = len(fixed_features)\n",
    "max_features = fixed_features_len + len(labels) - 2\n",
    "\n",
    "mapes = []\n",
    "\n",
    "for idx in range(n_samples):\n",
    "    input = val_loader.dataset[idx][0][fixed_labels_len]\n",
    "    output = sample_from_model(model, input, sequence_length, fixed_features_len, fixed_labels_len, max_features, device)\n",
    "    \n",
    "    target = convert(val_loader.dataset[idx][1].reshape(-1))\n",
    "    output = convert(output.reshape(-1))\n",
    "    \n",
    "    #print(output)\n",
    "    #print(target)\n",
    "    \n",
    "    mapes.append(calculate_mape(target, output))\n",
    "\n",
    "    if (idx+1) % 100 == 0:\n",
    "        print(idx+1)\n",
    "\n",
    "np.mean(mapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "f98c960f-1bbe-44da-8d37-f26fae79bd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "[75.25655627772213, 50.31497908197343, 42.92279181443155, 38.64239037632942, 35.593322809785604, 33.093244361132385, 31.262917769886553, 29.305142525583506, 27.551480570062996, 25.754940614663063, 23.84885540297255, 22.35988664170727, 20.450180342793466, 18.69448260795325, 17.0201595001854, 15.231713772471995, 13.520954349264503, 11.926851070998236, 10.396295081684366, 8.944350967742503, 7.520265502529218, 6.1192999195773154, 4.780234487855341, 3.509259929810651, 2.300726163591025, 1.1484063471230912, 0.06026516933452512]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "sequence_length = 27\n",
    "fixed_features_len = len(fixed_features)\n",
    "max_features = fixed_features_len + len(labels) - 2\n",
    "\n",
    "total_mapes = []\n",
    "\n",
    "for j in range(sequence_length):\n",
    "    fixed_labels_len = j\n",
    "    \n",
    "    mapes = []\n",
    "    \n",
    "    for idx in range(n_samples):\n",
    "        input = val_loader.dataset[idx][0][fixed_labels_len]\n",
    "        output = sample_from_model(model, input, sequence_length, fixed_features_len, fixed_labels_len, max_features, device)\n",
    "        \n",
    "        target = convert(val_loader.dataset[idx][1].reshape(-1))\n",
    "        output = convert(output.reshape(-1))\n",
    "        \n",
    "        mapes.append(calculate_mape(target, output))\n",
    "    \n",
    "        if (idx+1) % 1000 == 0:\n",
    "            print(idx+1)\n",
    "\n",
    "    total_mapes.append(np.mean(mapes))\n",
    "\n",
    "print(total_mapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "88293ed4-00bf-4c03-9b24-a4a088d4229e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4675,  0.6046],\n",
       "        [-0.6800,  0.8129],\n",
       "        [-0.7581,  0.8897],\n",
       "        [-0.7990,  0.9032],\n",
       "        [-0.8237,  0.8701],\n",
       "        [-0.8398,  0.8017],\n",
       "        [-0.8506,  0.7071],\n",
       "        [-0.8579,  0.5933],\n",
       "        [-0.8626,  0.4660],\n",
       "        [-0.8654,  0.3295],\n",
       "        [-0.8669,  0.1872],\n",
       "        [-0.8673,  0.0418],\n",
       "        [-0.8668, -0.1046],\n",
       "        [-0.8640, -0.3947],\n",
       "        [-0.8597, -0.6742],\n",
       "        [-0.8543, -0.9384],\n",
       "        [-0.8455, -1.3009],\n",
       "        [-0.8364, -1.6213],\n",
       "        [-0.8247, -1.9857],\n",
       "        [-0.8090, -2.4155],\n",
       "        [-0.7940, -2.7782],\n",
       "        [-0.7794, -3.0925],\n",
       "        [-0.7650, -3.3635],\n",
       "        [-0.7526, -3.5639],\n",
       "        [-0.7416, -3.7089],\n",
       "        [-0.7340, -3.7847],\n",
       "        [-0.7300, -3.8136]], device='cuda:0')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader.dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a025c5c-facc-4edd-bf37-185dea5b8687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.0329, -0.9242,  0.5207, -0.2964,  0.1727, -0.7080,  1.2338, -0.4675,\n",
       "         0.6046,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader.dataset[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "44009aa2-960a-451e-87b9-2721cb5c7987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.28389615, -0.00085208],\n",
       "        [ 0.28396317, -0.00254925],\n",
       "        [ 0.28409564, -0.00422577],\n",
       "        [ 0.28429055, -0.00586867],\n",
       "        [ 0.28454363, -0.00746612],\n",
       "        [ 0.28484967, -0.00900773],\n",
       "        [ 0.28520283, -0.01048475],\n",
       "        [ 0.28559682, -0.01189018],\n",
       "        [ 0.28602538, -0.01321872],\n",
       "        [ 0.2864823 , -0.01446671],\n",
       "        [ 0.28696173, -0.01563198],\n",
       "        [ 0.28745827, -0.01671367],\n",
       "        [ 0.287967  , -0.01771205],\n",
       "        [ 0.28900412, -0.01946452],\n",
       "        [ 0.29004437, -0.02090727],\n",
       "        [ 0.29106668, -0.02206569],\n",
       "        [ 0.29253575, -0.02333438],\n",
       "        [ 0.29390275, -0.02413065],\n",
       "        [ 0.29554573, -0.02462128],\n",
       "        [ 0.29762554, -0.02451147],\n",
       "        [ 0.2995346 , -0.02364393],\n",
       "        [ 0.30134875, -0.02203338],\n",
       "        [ 0.30310032, -0.01955435],\n",
       "        [ 0.3045955 , -0.01640292],\n",
       "        [ 0.3059083 , -0.01225413],\n",
       "        [ 0.3068087 , -0.00762098],\n",
       "        [ 0.30727825, -0.0025785 ]], dtype=float32),\n",
       " array([[ 0.29420874, -0.00466167],\n",
       "        [ 0.29355952, -0.00438461],\n",
       "        [ 0.2906969 , -0.00547059],\n",
       "        [ 0.288009  , -0.0073858 ],\n",
       "        [ 0.28857872, -0.00917243],\n",
       "        [ 0.28942943, -0.01086442],\n",
       "        [ 0.29087743, -0.0125124 ],\n",
       "        [ 0.29156542, -0.01369904],\n",
       "        [ 0.29184613, -0.01445723],\n",
       "        [ 0.2922154 , -0.01513941],\n",
       "        [ 0.29223597, -0.01582516],\n",
       "        [ 0.29268676, -0.01649612],\n",
       "        [ 0.2938672 , -0.01729642],\n",
       "        [ 0.29424357, -0.01834384],\n",
       "        [ 0.2950107 , -0.01925173],\n",
       "        [ 0.29465947, -0.0200884 ],\n",
       "        [ 0.29604363, -0.02095788],\n",
       "        [ 0.2966129 , -0.02154944],\n",
       "        [ 0.2984737 , -0.02181433],\n",
       "        [ 0.30178308, -0.02154872],\n",
       "        [ 0.37240976, -0.00916567],\n",
       "        [ 0.37236258, -0.0077083 ],\n",
       "        [ 0.37231362, -0.00627176],\n",
       "        [ 0.37225217, -0.00492241],\n",
       "        [ 0.3721849 , -0.00348937],\n",
       "        [ 0.37210077, -0.00209763],\n",
       "        [ 0.37199995, -0.00069646]], dtype=float32))"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "input = val_loader.dataset[idx][0][0]\n",
    "input2 = val_loader.dataset[idx][0][1]\n",
    "target = val_loader.dataset[idx][1]\n",
    "\n",
    "#context = torch.zeros(1, 27, 59, device = device)\n",
    "#context[0, 0] = input\n",
    "\n",
    "context = input.repeat(1, 27, 1)\n",
    "\n",
    "for i in range(20):\n",
    "    context[0, i] = val_loader.dataset[idx][0][i]\n",
    "\n",
    "\n",
    "#context = input2.repeat(1, 27, 1)\n",
    "#context[0, 1] = input2.repeat(1, 26, 1)\n",
    "context.shape\n",
    "\n",
    "#print(context)\n",
    "\n",
    "#print(context[0][0])\n",
    "#print(context[0][1])\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(context)\n",
    "    #print(output)\n",
    "    #print(target)\n",
    "\n",
    "# [2.8375185e-01 2.7025037e-04]\n",
    "#[ 0.28389615 -0.00085208]\n",
    "\n",
    "target = convert(target.reshape(-1))\n",
    "output = convert(output.reshape(-1))\n",
    "\n",
    "target, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "d1a428c1-0412-4865-9e3c-b30e3ba5fa66",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (94715631.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[413], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(input)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "input = val_loader.dataset[idx][0][start_with_n_labels]\n",
    "\n",
    "original_input = input.clone()\n",
    "    print(input)\n",
    "    input = F.pad(input, (0, max_features - input.size(0)))\n",
    "    print(input)\n",
    "    context = input.repeat(1, sequence_length, 1)\n",
    "    outputs = torch.tensor(np.zeros((sequence_length, 2)), device=device)\n",
    "\n",
    "    #print(context.shape)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i in range(start, sequence_length):\n",
    "\n",
    "            #print(context[0][:7])\n",
    "            output = model(context)\n",
    "            \n",
    "            prediction = output[:, -1:, :].reshape(-1) # get the last item\n",
    "\n",
    "            #print(prediction)\n",
    "            outputs[i] = prediction\n",
    "\n",
    "            if i+1 == sequence_length: \n",
    "                break\n",
    "            \n",
    "            # Append the next item to the generated sequence\n",
    "            test = torch.cat((original_input, outputs[:i+1].reshape(-1)), dim=0)\n",
    "            #print(test.shape)\n",
    "            context[0, i+1, :] = F.pad(test, (0, max_features - test.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "0d3d262e-db3f-4c86-a9a4-4ecfd4866043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28438747, -0.03047266],\n",
       "       [ 0.2913718 , -0.05072586],\n",
       "       [ 0.30114108, -0.05112787],\n",
       "       [ 0.30832806, -0.04617152],\n",
       "       [ 0.31295744, -0.04065794],\n",
       "       [ 0.31593782, -0.0357836 ],\n",
       "       [ 0.31791824, -0.03171095],\n",
       "       [ 0.31928274, -0.02834773],\n",
       "       [ 0.3202551 , -0.02556159],\n",
       "       [ 0.3209689 , -0.02323411],\n",
       "       [ 0.3215065 , -0.02127034],\n",
       "       [ 0.32192057, -0.0195967 ],\n",
       "       [ 0.32224572, -0.01815656],\n",
       "       [ 0.3227158 , -0.01581195],\n",
       "       [ 0.32303217, -0.01399025],\n",
       "       [ 0.3232548 , -0.01253754],\n",
       "       [ 0.32348233, -0.0108408 ],\n",
       "       [ 0.32363304, -0.00954406],\n",
       "       [ 0.3237658 , -0.00822783],\n",
       "       [ 0.323886  , -0.00681435],\n",
       "       [ 0.32396623, -0.00567463],\n",
       "       [ 0.3240247 , -0.00466912],\n",
       "       [ 0.32406953, -0.00371678],\n",
       "       [ 0.32410103, -0.00286272],\n",
       "       [ 0.3241247 , -0.00199403],\n",
       "       [ 0.3241391 , -0.00118479],\n",
       "       [ 0.3241461 , -0.00039172]], dtype=float32)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = convert(train_loader.dataset[1][1].reshape(-1))\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "67cf9193-6130-4ef4-a8de-de8bc711ecda",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[290], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m output\n",
      "Cell \u001b[1;32mIn[282], line 2\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(data):\n\u001b[1;32m----> 2\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      4\u001b[0m     r \u001b[38;5;241m=\u001b[39m label_r_scaler\u001b[38;5;241m.\u001b[39minverse_transform(data[::\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m     i \u001b[38;5;241m=\u001b[39m label_i_scaler\u001b[38;5;241m.\u001b[39minverse_transform(data[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "output = convert(output[7:])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3c9056-b10c-453d-b5f1-70f7d44491b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_mape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcalculate_mape\u001b[49m(target, output)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'calculate_mape' is not defined"
     ]
    }
   ],
   "source": [
    "calculate_mape(target, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24bf4df-aa06-4313-bdae-7a8f49c969f7",
   "metadata": {},
   "source": [
    "### Todos and other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "3565f571-6ab8-4d35-87ae-55f2d3c320d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_manual(model, val_loader, idx, seq, criterion, device):\n",
    "    model.eval()\n",
    "    #total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, targets in val_loader:\n",
    "\n",
    "            print(inputs[0].reshape(1, 27, 59).shape)\n",
    "            \n",
    "            outputs = model(inputs[0].reshape(1, 27, 59))\n",
    "            ##loss = criterion(outputs, targets)\n",
    "\n",
    "            #target = targets[idx]\n",
    "            #out = outputs[idx]\n",
    "            \n",
    "            target = convert(targets, idx)\n",
    "            out = convert(outputs, idx)\n",
    "\n",
    "            actual = out\n",
    "            exptected = target\n",
    "\n",
    "            print(actual[seq])\n",
    "            print(exptected[seq])\n",
    "            \n",
    "            #total_loss += loss.item()\n",
    "\n",
    "            break\n",
    "    \n",
    "    return actual, exptected, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "5c752183-b86a-409b-81c1-0e822cd725bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(targets, idx):\n",
    "    target_seq = targets.cpu().numpy()\n",
    "            \n",
    "    r = label_r_scaler.inverse_transform(target_seq[idx, :, ::2].reshape(1, -1)).reshape(-1, 1)\n",
    "    i = label_i_scaler.inverse_transform(target_seq[idx, :, 1::2].reshape(1, -1)).reshape(-1, 1)\n",
    "            \n",
    "    return np.concatenate((r, i), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "20625d5e-984a-4be0-a0f4-44a866d8591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(true_values, predictions, epsilon=1e-8):\n",
    "    # Ensure true_values and predictions are numpy arrays\n",
    "    true_values = np.array(true_values)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    # Calculate MAPE\n",
    "    mape = np.mean(np.abs((true_values - predictions) / (true_values + epsilon))) * 100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "8d260942-0cd4-4f14-9dbc-4fa5d7b12446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 27, 59])\n",
      "[2.8375185e-01 2.7025037e-04]\n",
      "[ 0.28389615 -0.00085208]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 131.71827010002053)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "seq = 0\n",
    "actual, exptected, loss = validate_manual(model, val_loader, idx, seq, criterion, device)\n",
    "loss, calculate_mape(exptected[seq][1], actual[seq][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b83e97-9759-4b47-b816-253efc867888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "345de053-b111-4c74-b9f2-2b5dad5d2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(model, input, sequence_length, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for _ in range(sequence_length):\n",
    "            output = model(input)\n",
    "            print(output)\n",
    "            next_item = output[:, -1:, :].repeat(1, sequence_length, 1)\n",
    "    \n",
    "            print(next_item)\n",
    "    \n",
    "            # Append the next item to the generated sequence\n",
    "            sample = torch.cat((sample, next_item), dim=2)\n",
    "            print(sample[0][0])\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f738932-18a7-4037-9f19-05e329a7fd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2844, -0.0305], device='cuda:0')\n",
      "tensor([[[-0.0002,  0.0046],\n",
      "         [ 0.0017,  0.0091],\n",
      "         [ 0.0020,  0.0091],\n",
      "         [ 0.0021,  0.0091],\n",
      "         [ 0.0022,  0.0091],\n",
      "         [ 0.0022,  0.0091],\n",
      "         [ 0.0022,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0091],\n",
      "         [ 0.0023,  0.0090],\n",
      "         [ 0.0023,  0.0090],\n",
      "         [ 0.0023,  0.0090],\n",
      "         [ 0.0023,  0.0090],\n",
      "         [ 0.0023,  0.0090],\n",
      "         [ 0.0023,  0.0090],\n",
      "         [ 0.0023,  0.0090],\n",
      "         [ 0.0023,  0.0090]]], device='cuda:0')\n",
      "tensor([[[0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090],\n",
      "         [0.0023, 0.0090]]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'sample' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m sample\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m---> 13\u001b[0m \u001b[43msample_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#sample = sample.repeat(sequence_length, 1).unsqueeze(0)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#sample, label\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 13\u001b[0m, in \u001b[0;36msample_from_model\u001b[1;34m(model, input, sequence_length, device)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(next_item)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Append the next item to the generated sequence\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     sample \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[43msample\u001b[49m, next_item), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sample[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'sample' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "sequence_length = 27\n",
    "\n",
    "input = torch.tensor(np.zeros((1, sequence_length, 59), dtype='f'), device=device)\n",
    "\n",
    "sample = train_loader.dataset[1][0][0]\n",
    "label = train_loader.dataset[1][1][0]\n",
    "\n",
    "print(label)\n",
    "\n",
    "input[0, 0] = sample\n",
    "input.shape\n",
    "\n",
    "sample_from_model(model, input, sequence_length, device)\n",
    "\n",
    "#sample = sample.repeat(sequence_length, 1).unsqueeze(0)\n",
    "#sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5f37f518-fbab-4df9-836c-548af2c83878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5402, -0.1061],\n",
      "         [ 0.0693,  0.0009],\n",
      "         [ 0.0704,  0.0061],\n",
      "         [ 0.0706,  0.0067],\n",
      "         [ 0.0711,  0.0064],\n",
      "         [ 0.0728,  0.0051],\n",
      "         [ 0.0737,  0.0050],\n",
      "         [ 0.0733,  0.0046],\n",
      "         [ 0.0707,  0.0041],\n",
      "         [ 0.0728,  0.0033],\n",
      "         [ 0.0723,  0.0032],\n",
      "         [ 0.0749,  0.0023],\n",
      "         [ 0.0775,  0.0009],\n",
      "         [ 0.0788,  0.0010],\n",
      "         [ 0.0794,  0.0011],\n",
      "         [ 0.0794,  0.0015],\n",
      "         [ 0.0799,  0.0017],\n",
      "         [ 0.0803,  0.0018],\n",
      "         [ 0.0823,  0.0019],\n",
      "         [ 0.0821,  0.0027],\n",
      "         [ 0.0801,  0.0032],\n",
      "         [ 0.0813,  0.0030],\n",
      "         [ 0.0824,  0.0020],\n",
      "         [ 0.0824,  0.0021],\n",
      "         [ 0.0823,  0.0021],\n",
      "         [ 0.0840,  0.0013],\n",
      "         [ 0.0852,  0.0007]]], device='cuda:0')\n",
      "tensor([[[0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007],\n",
      "         [0.0852, 0.0007]]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(next_item)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Append the next item to the generated sequence\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_item\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(sample[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 2)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    for _ in range(sequence_length):\n",
    "        output = model(input)\n",
    "        print(output)\n",
    "        next_item = output[:, -1:, :].repeat(1, sequence_length, 1)\n",
    "\n",
    "        print(next_item)\n",
    "\n",
    "        # Append the next item to the generated sequence\n",
    "        sample = torch.cat((sample, next_item), dim=2)\n",
    "        print(sample[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18f2ccf6-ab8c-48b8-96cd-ccca5684a7fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moutput\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc48dce1-403e-4651-9d31-eea20aeb3987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000151"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 0.151 * 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0ffd0c4-1771-479c-b1a3-d01d8d7d5a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6e-05"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.046 * 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e1846d-dc34-4c9b-b5f1-34b2bcb5ca2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
