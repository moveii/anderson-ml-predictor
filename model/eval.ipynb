{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Berger, 2024\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Union\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import AutoregressiveTransformer, ModelConfig\n",
    "from dataset import ImpurityDataset\n",
    "from columns import encoder_input, labels, tau_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG: Dict[str, Union[int, float, str, bool]] = {\n",
    "    \"seed\": 42,\n",
    "    \"dataset_path\": \"data/data_50k.csv\",\n",
    "    \"model_checkpoint\": \"model/model.pth\",\n",
    "    \"batch_size\": 32,\n",
    "    \"validation_size\": 0.1,\n",
    "    \"test_size\": 0.1,\n",
    "    \"use_scaling\": True,\n",
    "    \"pair_up_labels\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration (ensure this matches your trained model)\n",
    "MODEL_CONFIG = ModelConfig(\n",
    "    output_dim=2 if CONFIG[\"pair_up_labels\"] else 1,\n",
    "    d_model=256,\n",
    "    encoder_max_seq_length=len(encoder_input),\n",
    "    encoder_input_dim=1,\n",
    "    encoder_dim_feedforward=256 * 4,\n",
    "    encoder_nhead=4,\n",
    "    encoder_num_layers=4,\n",
    "    decoder_max_seq_length=len(labels) // (2 if CONFIG[\"pair_up_labels\"] else 1),\n",
    "    decoder_input_dim=2 if CONFIG[\"pair_up_labels\"] else 1,\n",
    "    decoder_dim_feedforward=256 * 4,\n",
    "    decoder_nhead=4,\n",
    "    decoder_num_layers=4,\n",
    "    dropout=0.1,\n",
    "    activation=\"gelu\",\n",
    "    bias=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAPELoss(nn.Module):\n",
    "    \"\"\"Custom Mean Absolute Percentage Error (MAPE) loss function.\"\"\"\n",
    "\n",
    "    def __init__(self, scaler, epsilon: float = 1e-8):\n",
    "        super(MAPELoss, self).__init__()\n",
    "        self.scaler = scaler\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, outputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the MAPE loss.\n",
    "\n",
    "        Args:\n",
    "            outputs (torch.Tensor): Predicted values\n",
    "            targets (torch.Tensor): True values\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Computed MAPE loss\n",
    "        \"\"\"\n",
    "        B, T, C = outputs.shape\n",
    "        device = outputs.device\n",
    "\n",
    "        outputs = outputs.view(B, T * C)\n",
    "        targets = targets.view(B, T * C)\n",
    "\n",
    "        if self.scaler != None:\n",
    "            scale = torch.tensor(self.scaler.scale_).to(device)\n",
    "            mean = torch.tensor(self.scaler.mean_).to(device)\n",
    "\n",
    "            outputs = outputs * scale + mean\n",
    "            targets = targets * scale + mean\n",
    "\n",
    "            outputs = outputs.view(B, T, C)\n",
    "            targets = targets.view(B, T, C)\n",
    "\n",
    "        diff = torch.abs(targets - outputs)\n",
    "        norm = torch.norm(targets, p=2, dim=1, keepdim=True)\n",
    "        ape = diff / (norm + self.epsilon)\n",
    "\n",
    "        return torch.mean(ape) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = CONFIG[\"seed\"]\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoregressiveTransformer(MODEL_CONFIG, device).to(device)\n",
    "model.load_state_dict(torch.load(CONFIG[\"model_checkpoint\"], map_location=device));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CONFIG[\"dataset_path\"])\n",
    "\n",
    "dataset = ImpurityDataset(\n",
    "    df[encoder_input + labels],\n",
    "    encoder_input,\n",
    "    labels,\n",
    "    CONFIG[\"pair_up_labels\"],\n",
    "    CONFIG[\"use_scaling\"],\n",
    "    CONFIG[\"validation_size\"],\n",
    "    CONFIG[\"test_size\"],\n",
    "    device=device,\n",
    "    seed=CONFIG[\"seed\"],\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(dataset.get_test_dataset(), batch_size=CONFIG[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MAPELoss(dataset.label_scaler).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, encoder_input, targets, num_initial_targets, max_length, pair_up_labels, device):\n",
    "    model.eval()\n",
    "    encoder_input = encoder_input.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_output = model.encode(encoder_input)\n",
    "\n",
    "        start_token = [0, 0] if pair_up_labels else [0]\n",
    "        start_token_tensor = torch.tensor([start_token], dtype=torch.float).to(device)\n",
    "        decoder_input = start_token_tensor.expand(encoder_input.size(0), 1, -1)\n",
    "\n",
    "        if num_initial_targets > 0:\n",
    "            decoder_input = torch.cat((decoder_input, targets[:, :num_initial_targets, :]), dim=1)\n",
    "\n",
    "        while decoder_input.size(1) < max_length + 1:  # +1 for the start token\n",
    "            output = model.decode(decoder_input, encoder_output)\n",
    "            next_token = output[:, -1:, :]\n",
    "            decoder_input = torch.cat((decoder_input, next_token), dim=1)\n",
    "\n",
    "    return decoder_input[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for encoder_input, decoder_input, targets in loader:\n",
    "            \n",
    "            outputs = model(encoder_input, decoder_input)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(test_loader)\n",
    "\n",
    "def evaluate_autoregressive(model, test_loader, criterion, pair_up_labels, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoder_input, _, targets in test_loader:\n",
    "            \n",
    "            outputs = sample(model, encoder_input, targets, 0, targets.size(1), pair_up_labels, device)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losss = evaluate(model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_losss:.4f}\")\n",
    "\n",
    "test_ar_losss = evaluate_autoregressive(model, test_loader, criterion, CONFIG[\"pair_up_labels\"], device)\n",
    "print(f\"Autoregressive Test Loss: {test_ar_losss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_list(model, test_loader, criterion, pair_up_labels, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoder_input, _, targets in test_loader:\n",
    "            \n",
    "            outputs = sample(model, encoder_input, targets, 0, targets.size(1), pair_up_labels, device)\n",
    "            loss = criterion(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return losses\n",
    "\n",
    "losses = evaluate_list(model, test_loader, criterion, CONFIG[\"pair_up_labels\"], device)\n",
    "enumerated = list(enumerate(losses))\n",
    "sorted_with_indices = sorted(enumerated, key=lambda x: x[1])\n",
    "sorted_with_indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "input = dataset.get_test_dataset().__getitem__(index)[0].reshape(1, -1, 1)\n",
    "targets = dataset.get_test_dataset().__getitem__(index)[2].reshape(1, -1, 2 if CONFIG[\"pair_up_labels\"] else 1)\n",
    "\n",
    "outputs = sample(model, input, targets, 0, len(labels) // (2 if CONFIG[\"pair_up_labels\"] else 1), CONFIG[\"pair_up_labels\"], device)\n",
    "\n",
    "loss = criterion(outputs, targets)\n",
    "print(loss)\n",
    "\n",
    "B, T, C = outputs.shape\n",
    "device = outputs.device\n",
    "\n",
    "outputs = outputs.view(B, T * C)\n",
    "targets = targets.view(B, T * C)\n",
    "\n",
    "if dataset.label_scaler != None:\n",
    "    scale = torch.tensor(dataset.label_scaler.scale_).to(device)\n",
    "    mean = torch.tensor(dataset.label_scaler.mean_).to(device)\n",
    "\n",
    "    outputs = outputs * scale + mean\n",
    "    targets = targets * scale + mean\n",
    "\n",
    "    outputs = outputs.view(B, T, C)\n",
    "    targets = targets.view(B, T, C)\n",
    "\n",
    "ape = torch.abs(targets - outputs) / torch.abs(targets + 1e-8)\n",
    "mape = torch.mean(ape) * 100\n",
    "\n",
    "outputs = outputs.cpu().numpy().squeeze()\n",
    "targets = targets.cpu().numpy().squeeze()\n",
    "\n",
    "if CONFIG[\"pair_up_labels\"]:\n",
    "    reshaped_array = outputs[:, 0]\n",
    "    reversed_second_column = np.flip(outputs[:, 1])\n",
    "    outputs = np.concatenate([reshaped_array, reversed_second_column])\n",
    "\n",
    "    reshaped_array = targets[:, 0]\n",
    "    reversed_second_column = np.flip(targets[:, 1])\n",
    "    targets = np.concatenate([reshaped_array, reversed_second_column])\n",
    "   \n",
    "taus = df[(df['sigma_tau_122'] <= targets[-1].item() + 1e-8) &(df['sigma_tau_122'] >= targets[-1].item() - 1e-8)][tau_columns].values.squeeze()\n",
    "\n",
    "sigma_over_tau = pd.DataFrame({\n",
    "    'taus': taus,\n",
    "    'outputs': outputs,\n",
    "    'targets': targets\n",
    "})\n",
    "\n",
    "# Save both to CSV files\n",
    "sigma_over_tau.to_csv(f'observation_{index+1}.csv', index=False)\n",
    "\n",
    "plt.plot(abs(outputs), label='Model Output', marker='o')\n",
    "plt.plot(abs(targets), label='Target', marker='x')\n",
    "plt.title(f'Comparison for Sample {index} - Dimension 1')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "#plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
