{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Berger, 2024\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Union\n",
    "\n",
    "from model import AutoregressiveTransformer, ModelConfig\n",
    "from dataset import ImpurityDataset\n",
    "from columns import encoder_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG: Dict[str, Union[int, float, str, bool]] = {\n",
    "    \"seed\": 42,\n",
    "    \"dataset_path\": \"data/data_50k.csv\",\n",
    "    \"model_checkpoint\": \"model/model-2024-09-19.pth\",\n",
    "    \"batch_size\": 32,\n",
    "    \"validation_size\": 0.1,\n",
    "    \"test_size\": 0.1,\n",
    "    \"use_scaling\": True,\n",
    "    \"pair_up_labels\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration (ensure this matches your trained model)\n",
    "MODEL_CONFIG = ModelConfig(\n",
    "    output_dim=2 if CONFIG[\"pair_up_labels\"] else 1,\n",
    "    d_model=256,\n",
    "    encoder_max_seq_length=len(encoder_input),\n",
    "    encoder_input_dim=1,\n",
    "    encoder_dim_feedforward=256 * 4,\n",
    "    encoder_nhead=4,\n",
    "    encoder_num_layers=4,\n",
    "    decoder_max_seq_length=len(labels) // (2 if CONFIG[\"pair_up_labels\"] else 1),\n",
    "    decoder_input_dim=2 if CONFIG[\"pair_up_labels\"] else 1,\n",
    "    decoder_dim_feedforward=256 * 4,\n",
    "    decoder_nhead=4,\n",
    "    decoder_num_layers=4,\n",
    "    dropout=0.1,\n",
    "    activation=\"gelu\",\n",
    "    bias=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAPELoss(nn.Module):\n",
    "    \"\"\"Custom Mean Absolute Percentage Error (MAPE) loss function.\"\"\"\n",
    "\n",
    "    def __init__(self, scaler, epsilon: float = 1e-8):\n",
    "        super(MAPELoss, self).__init__()\n",
    "        self.scaler = scaler\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, outputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the MAPE loss.\n",
    "\n",
    "        Args:\n",
    "            outputs (torch.Tensor): Predicted values\n",
    "            targets (torch.Tensor): True values\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Computed MAPE loss\n",
    "        \"\"\"\n",
    "        B, T, C = outputs.shape\n",
    "        device = outputs.device\n",
    "\n",
    "        outputs = outputs.view(B, T * C)\n",
    "        targets = targets.view(B, T * C)\n",
    "\n",
    "        if self.scaler != None:\n",
    "            scale = torch.tensor(self.scaler.scale_).to(device)\n",
    "            mean = torch.tensor(self.scaler.mean_).to(device)\n",
    "\n",
    "            outputs = outputs * scale + mean\n",
    "            targets = targets * scale + mean\n",
    "\n",
    "            outputs = outputs.view(B, T, C)\n",
    "            targets = targets.view(B, T, C)\n",
    "\n",
    "        diff = torch.abs(targets - outputs)\n",
    "        norm = torch.norm(targets, p=2, dim=1, keepdim=True)\n",
    "        ape = diff / (norm + self.epsilon)\n",
    "\n",
    "        return torch.mean(ape) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = CONFIG[\"seed\"]\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoregressiveTransformer(MODEL_CONFIG, device).to(device)\n",
    "model.load_state_dict(torch.load(CONFIG[\"model_checkpoint\"], map_location=device));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CONFIG[\"dataset_path\"])\n",
    "\n",
    "dataset = ImpurityDataset(\n",
    "    df[encoder_input + labels],\n",
    "    encoder_input,\n",
    "    labels,\n",
    "    CONFIG[\"pair_up_labels\"],\n",
    "    CONFIG[\"use_scaling\"],\n",
    "    CONFIG[\"validation_size\"],\n",
    "    CONFIG[\"test_size\"],\n",
    "    device=device,\n",
    "    seed=CONFIG[\"seed\"],\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(dataset.get_test_dataset(), batch_size=CONFIG[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MAPELoss(dataset.label_scaler).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, encoder_input, targets, num_initial_targets, max_length, pair_up_labels, device):\n",
    "    model.eval()\n",
    "    encoder_input = encoder_input.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_output = model.encode(encoder_input)\n",
    "\n",
    "        start_token = [0, 0] if pair_up_labels else [0]\n",
    "        start_token_tensor = torch.tensor([start_token], dtype=torch.float).to(device)\n",
    "        decoder_input = start_token_tensor.expand(encoder_input.size(0), 1, -1)\n",
    "\n",
    "        if num_initial_targets > 0:\n",
    "            decoder_input = torch.cat((decoder_input, targets[:, :num_initial_targets, :]), dim=1)\n",
    "\n",
    "        while decoder_input.size(1) < max_length + 1:  # +1 for the start token\n",
    "            output = model.decode(decoder_input, encoder_output)\n",
    "            next_token = output[:, -1:, :]\n",
    "            decoder_input = torch.cat((decoder_input, next_token), dim=1)\n",
    "\n",
    "    return decoder_input[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for encoder_input, decoder_input, targets in loader:\n",
    "\n",
    "            outputs = model(encoder_input, decoder_input)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(test_loader)\n",
    "\n",
    "def evaluate_autoregressive(model, test_loader, criterion, pair_up_labels, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoder_input, _, targets in test_loader:\n",
    "\n",
    "            outputs = sample(model, encoder_input, targets, 0, targets.size(1), pair_up_labels, device)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:685: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.3618\n",
      "Autoregressive Test Loss: 3.3892\n"
     ]
    }
   ],
   "source": [
    "test_losss = evaluate(model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_losss:.4f}\")\n",
    "\n",
    "test_ar_losss = evaluate_autoregressive(model, test_loader, criterion, CONFIG[\"pair_up_labels\"], device)\n",
    "print(f\"Autoregressive Test Loss: {test_ar_losss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
